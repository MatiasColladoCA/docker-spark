version: '4.0.1'

# Definimos una plantilla reutilizable para los workers de Spark.
# Cualquier servicio que use <<: *spark-worker-config heredará esta configuración.
x-spark-worker-template: &spark-worker-config
  build: .
  depends_on:
    - spark-master
  volumes:
    - ./data:/opt/spark/data
    - ./spark-events:/tmp/spark-events
  environment:
    - SPARK_WORKER_MEMORY=2g
    - SPARK_WORKER_CORES=2
    - SPARK_LOCAL_DIRS=/tmp
    - SPARK_WORKER_DIR=/tmp
  networks:
    - spark-net

services:
  spark-master:
    build: .
    container_name: spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./data:/opt/spark/data
      - ./spark-events:/tmp/spark-events
    environment:
      - SPARK_LOCAL_DIRS=/tmp
    networks:
      - spark-net

  # --- WORKERS ---
  # Ahora definimos cada worker heredando la configuración de la plantilla.
  # Solo cambiamos el nombre del contenedor y el comando.
  
  spark-worker-1:
    <<: *spark-worker-config
    container_name: spark-worker-1
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077

  spark-worker-2:
    <<: *spark-worker-config
    container_name: spark-worker-2
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077

  # spark-worker-3:
  #   <<: *spark-worker-config
  #   container_name: spark-worker-3
  #   command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077

  # spark-worker-4:
  #   <<: *spark-worker-config
  #   container_name: spark-worker-4
  #   command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077

  # spark-worker-5:
  #   <<: *spark-worker-config
  #   container_name: spark-worker-5
  #   command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077

  # spark-worker-6:
  #   <<: *spark-worker-config
  #   container_name: spark-worker-6
  #   command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077

  # spark-worker-7:
  #   <<: *spark-worker-config
  #   container_name: spark-worker-7
  #   command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077

  # spark-worker-8:
  #   <<: *spark-worker-config
  #   container_name: spark-worker-8
  #   command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077

  spark-client:
    build: .
    container_name: spark-client
    depends_on:
      - spark-master
    volumes:
      - ./data:/opt/spark/data
      - ./spark-events:/tmp/spark-events
    ports:
      - "4040:4040"
    command: ["sh", "-c", "sleep infinity"]
    networks:
      - spark-net

  spark-history-server:
    build: .
    container_name: spark-history-server
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.history.HistoryServer
    ports:
      - "18080:18080"
    volumes:
      - ./spark-events:/tmp/spark-events
    environment:
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=file:///tmp/spark-events -Dspark.history.ui.port=18080
      
    networks:
      - spark-net

networks:
  spark-net:
    driver: bridge